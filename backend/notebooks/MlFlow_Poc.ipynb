{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d117e013",
   "metadata": {},
   "source": [
    "# ML_Ops POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e74d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "#import mlflow.tensorflow\n",
    "#import tensorflow as tf\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from tensorflow import keras\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5c699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuelles Arbeitsverzeichnis: c:\\Zeug Hendrik\\Studium\\Master FH Meschede\\5 Semester\\MLOps\\Project\\FHSWF-MLOps\\backend\\notebooks\n",
      "c:\\Zeug Hendrik\\Studium\\Master FH Meschede\\5 Semester\\MLOps\\Project\\FHSWF-MLOps\n",
      "Origin from env:  data/origin\n",
      "Origin from env:  backend/mlruns\n",
      "data\\origin\n",
      "backend\\mlruns\n",
      "c:\\Zeug Hendrik\\Studium\\Master FH Meschede\\5 Semester\\MLOps\\Project\\FHSWF-MLOps\\data\\origin\n",
      "c:\\Zeug Hendrik\\Studium\\Master FH Meschede\\5 Semester\\MLOps\\Project\\FHSWF-MLOps\\backend\\mlruns\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "script_dir = Path(__file__).resolve().parent if \"__file__\" in globals() else Path(os.getcwd())\n",
    "\n",
    "print(f\"Aktuelles Arbeitsverzeichnis: {os.getcwd()}\")\n",
    "\n",
    "root_dir = script_dir.parent.parent\n",
    "\n",
    "print(root_dir)\n",
    "\n",
    "data_path = os.getenv(\"DATA_PATH\")\n",
    "mlflowUri = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "print('Origin from env: ' , data_path)\n",
    "print('Origin from env: ' , mlflowUri)\n",
    "\n",
    "\n",
    "data_path = Path(data_path)\n",
    "mlflowUri = Path(mlflowUri)\n",
    "\n",
    "print(data_path)\n",
    "print(mlflowUri)\n",
    "\n",
    "if not data_path.is_absolute():\n",
    "    data_path = root_dir / data_path\n",
    "\n",
    "if not mlflowUri.is_absolute():\n",
    "    mlflowUri = root_dir / mlflowUri\n",
    "\n",
    "print(data_path)\n",
    "print(mlflowUri)\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(mlflowUri)\n",
    "df = pd.read_csv(data_path / \"adult.csv\", names=columns, na_values=\" ?\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "250b1014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Zeug Hendrik\\Studium\\Master FH Meschede\\5 Semester\\MLOps\\Project\\FHSWF-MLOps\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b5b27932a94d6aa2071b42bbdeff44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'random_forest_pipeline' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'random_forest_pipeline'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8601064555752695, F1 Score: 0.6805858522904331\n"
     ]
    }
   ],
   "source": [
    "columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "mlflow.set_tracking_uri(mlflowUri)\n",
    "df = pd.read_csv(data_path / \"adult.csv\", names=columns, na_values=\" ?\", header=0)\n",
    "\n",
    "# Fehlende Werte entfernen\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Zielvariable in boolschen Wert umwandeln\n",
    "df[\"income\"] = df[\"income\"].apply(lambda x: 1 if x == \">50K\" else 0)\n",
    "\n",
    "# Kategorische Variablen kodieren\n",
    "categorical_features = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "\n",
    "\n",
    "X = df.drop(\"income\", axis=1)\n",
    "y = df[\"income\"]\n",
    "\n",
    "# Daten in Trainings- und Testset aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', MinMaxScaler(), X_train.select_dtypes(include=['int64', 'float64']).columns),  # Numerische Variablen skalieren\n",
    "            ('cat', Pipeline([\n",
    "                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]), categorical_features)  # Kategorische Variablen\n",
    "        ]\n",
    "    )),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42))  # Klassifikator\n",
    "])\n",
    "\n",
    "# MLflow Experiment: Random Forest\n",
    "mlflow.set_experiment(\"Random_Forest\")\n",
    "with mlflow.start_run() as run:\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Vorhersagen & Metriken berechnen\n",
    "    y_pred_rf = pipeline.predict(X_test)\n",
    "\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    f1 = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "    signature = infer_signature(X_train, pipeline.predict(X_train))\n",
    "    input_example = pd.DataFrame(X_train[:5], columns=X.columns).to_dict(orient=\"records\")\n",
    "\n",
    "    mlflow.log_param(\"model\", \"RandomForestClassifier\")\n",
    "    mlflow.log_metric(\"accuracy\", acc_rf)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.sklearn.log_model(pipeline, \"random_forest_model\", signature=signature, input_example=input_example)\n",
    "    \n",
    "    model_uri = f\"runs:/{run.info.run_id}/random_forest_pipeline\"\n",
    "    \n",
    "    modelversion = mlflow.register_model(model_uri=model_uri, name=\"random_forest_pipeline\")\n",
    "    \n",
    "    client = MlflowClient()\n",
    "    client.set_registered_model_alias(name='random_forest_pipeline', alias='newest', version=modelversion.version)\n",
    "    \n",
    "    best_model = None\n",
    "    best_f1 = 0\n",
    "    for mv in client.search_model_versions(f\"name='random_forest_pipeline'\"):\n",
    "        metrics = client.get_run(mv.run_id).data.metrics\n",
    "        if metrics[\"f1_score\"] > best_f1:\n",
    "            best_f1 = metrics[\"f1_score\"]\n",
    "            best_model = mv\n",
    "    \n",
    "    if best_model:\n",
    "        client.set_registered_model_alias(name='random_forest_pipeline', alias='best', version=best_model.version)\n",
    "    \n",
    "\n",
    "    print(f\"Accuracy: {acc_rf}, F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0a7e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'prediction': [1]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL mit den Parametern model und alias f√ºr lokalen FastAPI-Testserver\n",
    "url = \"http://127.0.0.1:8000/predict\"\n",
    "params = {\n",
    "    \"model\": \"RandomForestAdultIncome\",\n",
    "    \"alias\": \"newest\"\n",
    "}\n",
    "\n",
    "# Beispiel-Daten aus dem Adult-Income-Dataset\n",
    "body = {\n",
    "    \"age\": 39,\n",
    "    \"workclass\": \"State-gov\",\n",
    "    \"fnlwgt\": 77516,\n",
    "    \"education\": \"Bachelors\",\n",
    "    \"education-num\": 13,\n",
    "    \"marital-status\": \"Never-married\",\n",
    "    \"occupation\": \"Adm-clerical\",\n",
    "    \"relationship\": \"Not-in-family\",\n",
    "    \"race\": \"White\",\n",
    "    \"sex\": \"Male\",\n",
    "    \"capital-gain\": 500000,\n",
    "    \"capital-loss\": 0,\n",
    "    \"hours-per-week\": 40,\n",
    "    \"native-country\": \"United-States\"\n",
    "}\n",
    "\n",
    "# Request senden\n",
    "response = requests.post(url, params=params, json=body)\n",
    "\n",
    "# Antwort ausgeben\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e9c6633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehler beim Laden des Modells: No such file or directory: '/Users/developerhhotels/Documents/Projekte/Own Projects/MLOps/FHSWF-MLOps/backend/mlruns/747985668469723700/24dad1cdeb1740ba8e0ae3c95343bd64/artifacts/model'\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# FastAPI Initialisierung\n",
    "#app = FastAPI()\n",
    "\n",
    "# MLflow Client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Bestes Modell aus MLflow Production laden\n",
    "model_name = \"random_forest_pipeline\"\n",
    "try:\n",
    "    #model_uri = f\"models:/{model_name}/Production\"\n",
    "    run_id = client.get_model_version_by_alias('random_forest_pipeline','best').run_id\n",
    "    model_uri = \"runs:/{}/model\".format(run_id)\n",
    "\n",
    "    pymodel = mlflow.sklearn.load_model(model_uri)\n",
    "except Exception as e:\n",
    "    model = None\n",
    "    print(f\"Fehler beim Laden des Modells: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
